# 显存优化指南

## 当前显存需求评估

根据你的配置，显存需求大致如下：

### 基础显存需求（估算）

1. **模型参数**：
   - `Alibaba-NLP/gte-multilingual-base`: ~110M 参数 ≈ 440MB
   - 改进模型（MLP头）: 额外 ~1M 参数 ≈ 4MB
   - **总计**: ~450MB

2. **激活值（前向传播）**：
   - Batch size = 16, Max length = 512
   - 每样本: ~512 * 768 * 4 bytes ≈ 1.5MB
   - Batch: 16 * 1.5MB ≈ 24MB
   - **总计**: ~25MB

3. **梯度（反向传播）**：
   - 与模型参数相同: ~450MB

4. **优化器状态（AdamW）**：
   - 动量 + 方差: 2 * 450MB = 900MB

5. **其他开销**：
   - 临时变量、中间结果等: ~200-500MB

**总显存需求（估算）**: ~2-2.5GB（基础） + 批次大小相关开销

### 实际显存使用

根据你的错误信息，当前使用了约21GB显存，说明：
- 可能有其他进程占用显存
- 或者batch size较大
- 或者使用了改进模型（特征维度更大）

## 显存优化方案

### 1. 指定使用空闲GPU ⭐⭐⭐⭐⭐

**最简单有效的方法**

根据你的GPU状态，推荐使用：
- **GPU 4**: 剩余 18.9GB（最空闲）
- **GPU 6**: 剩余 20.0GB（次空闲）

**使用方法**：

在 `.env` 文件中添加：
```bash
GPU_ID=4
```

或者在命令行中设置：
```bash
export GPU_ID=4
python train.py
```

### 2. 减小Batch Size ⭐⭐⭐⭐

**预期节省**: 50-70% 显存

**方法**：
```bash
# 在.env文件中
BATCH_SIZE=8  # 从16减小到8，显存需求减半
# 或
BATCH_SIZE=4  # 更激进，显存需求减少75%
```

**注意**: 减小batch size可能影响训练稳定性，需要适当调整学习率。

### 3. 混合精度训练（FP16）⭐⭐⭐⭐⭐

**预期节省**: 40-50% 显存

**方法**：
```bash
# 在.env文件中
FP16=True
```

**优点**:
- 显存减半
- 训练速度提升（在支持的GPU上）
- 通常不影响精度

### 4. 梯度检查点（Gradient Checkpointing）⭐⭐⭐

**预期节省**: 30-40% 显存

**方法**：
```bash
# 在.env文件中
GRADIENT_CHECKPOINTING=True
```

**缺点**:
- 训练时间增加约20-30%
- 用计算时间换显存

### 5. 减小序列长度 ⭐⭐⭐

**预期节省**: 与长度成正比

**方法**：
```bash
# 在.env文件中
MAX_LENGTH=256  # 从512减小到256，显存需求减半
```

**注意**: 可能丢失长文本信息，需要权衡。

### 6. 组合使用（推荐）⭐⭐⭐⭐⭐

**最佳组合方案**：

```bash
# .env文件
GPU_ID=4                    # 使用空闲GPU
BATCH_SIZE=4                 # 减小batch size
FP16=True                    # 混合精度训练
GRADIENT_CHECKPOINTING=True  # 梯度检查点
MAX_LENGTH=384               # 稍微减小序列长度（可选）
```

**预期效果**:
- 显存需求: 从 ~2.5GB 降低到 ~0.8-1.2GB
- 训练速度: 可能稍慢（梯度检查点），但FP16会加速

## 快速解决方案

### 方案1: 快速解决（最小改动）

```bash
# 在.env文件中添加
GPU_ID=4
BATCH_SIZE=8
FP16=True
```

### 方案2: 激进优化（最大节省）

```bash
# 在.env文件中添加
GPU_ID=4
BATCH_SIZE=2
FP16=True
GRADIENT_CHECKPOINTING=True
MAX_LENGTH=384
```

## 显存监控

训练时可以使用以下命令监控显存：

```bash
# 实时监控
watch -n 1 nvidia-smi

# 或查看特定GPU
nvidia-smi -i 4
```

## 注意事项

1. **学习率**: 如果减小batch size，可能需要适当调整学习率
2. **FP16**: 在RTX 4090上完全支持，推荐使用
3. **梯度检查点**: 会增加训练时间，但可以显著节省显存

## 推荐配置（针对你的情况）

根据你的GPU状态（8个RTX 4090，每个24GB），推荐：

```bash
GPU_ID=4                    # 使用最空闲的GPU
BATCH_SIZE=8                 # 适中的batch size
FP16=True                    # 启用混合精度
GRADIENT_CHECKPOINTING=False # 如果显存够用就不启用
MAX_LENGTH=512               # 保持原长度
```

这样应该可以将显存需求控制在 1-1.5GB 左右，完全够用。

